"""
Gemini API Client cho T·∫°o Kh·∫£o s√°t (gemini_client)
X·ª≠ l√Ω giao ti·∫øp v·ªõi Google Gemini API ƒë·ªÉ t·∫°o kh·∫£o s√°t th√¥ng minh
"""

import json
import logging
import re,os
import time, random
from typing import Dict, Any, Optional, List
import requests
import base64 
from dataclasses import dataclass
try:
    from ..models.survey_schemas import GeneratedSurveyResponse
except Exception:
    from app.models.survey_schemas import GeneratedSurveyResponse

logger = logging.getLogger(__name__)

class GeminiOverloadedError(Exception):
    """N√©m khi Gemini qu√° t·∫£i (429/503) sau khi ƒë√£ retry."""
    pass

@dataclass
class GeminiConfig:
    api_key: str
    base_url: str = "https://generativelanguage.googleapis.com/v1beta"
    model: str = os.getenv("GEMINI_MODEL", "gemini-1.5-flash")
    temperature: float = 0.4
    max_tokens: int = 8192
    
    # Fallback chain: th·ª© t·ª± ∆∞u ti√™n models khi g·∫∑p rate limit
    fallback_models: List[str] = None
    
    def __post_init__(self):
        if self.fallback_models is None:
            # Ch·ªâ d√πng models c√≥ trong Google AI Studio free tier
            # D·ª±a v√†o quota: gemini-2.5-flash (5 RPM), gemini-2.5-flash-lite (10 RPM)
            self.fallback_models = [
                "gemini-2.5-flash",
                "gemini-2.5-flash-lite"
            ]

    # Alias ƒë·ªÉ code c≈© g·ªçi self.config.model_name v·∫´n ch·∫°y
    @property
    def model_name(self) -> str:
        return self.model

SURVEY_SCHEMA = {
    "type": "object",
    "properties": {
        "title": {"type": "string"},
        "description": {"type": "string"},
        "questions": {
            "type": "array",
            "items": {
                "type": "object",
                "properties": {
                    "question_text": {"type": "string"},
                    "question_type": {"type": "string"},
                    "options": {
                        "type": "array",
                        "items": {"type": "string"}
                    }
                },
                "required": ["question_text", "question_type"]
            }
        }
    },
    "required": ["questions"]
}

ONE_QUESTION_SCHEMA = {
    "type": "object",
    "properties": {
        "question_text": {"type": "string"},
        "question_type": {"type": "string"},
        "options": {
            "type": "array",
            "items": {"type": "string"}
        }
    },
    "required": ["question_text", "question_type"]
}

def _post_with_retry(self, url, payload, retries=4, timeout=45):
    last_err = None
    for i in range(retries):
        try:
            r = requests.post(url, headers=self.headers, json=payload, timeout=timeout)
            # N·∫øu server ƒëang qu√° t·∫£i ho·∫∑c rate limit => th·ª≠ l·∫°i
            if r.status_code in (429, 500, 502, 503, 504):
                raise requests.HTTPError(f"{r.status_code} {r.text}", response=r)
            r.raise_for_status()
            return r.json()
        except requests.HTTPError as e:
            status = getattr(e.response, "status_code", 0)
            if status in (429, 500, 502, 503, 504) and i < retries - 1:
                # Exponential backoff + jitter (1s, 2s, 4s, ...)
                time.sleep((2 ** i) + random.random())
                continue
            last_err = e
            break
        except requests.RequestException as e:
            last_err = e
            if i < retries - 1:
                time.sleep((2 ** i) + random.random())
                continue
            break
    if last_err:
        raise last_err

def _clean_option_text(s: str) -> str:
    if not s:
        return ""
    s = str(s).strip()
    # d·∫°ng: option_text='xxx' display_order=2  ->  xxx
    m = re.search(r"option_text\s*=\s*['\"]([^'\"]+)['\"]", s, flags=re.I)
    if m:
        return m.group(1).strip()
    # d·∫°ng: {'option_text': 'xxx', 'display_order': 1} -> kh·ª≠ chu·ªói
    m = re.search(r"'option_text'\s*:\s*'([^']+)'", s)
    if m:
        return m.group(1).strip()
    # n·∫øu ch·ªâ l√† "L·ª±a ch·ªçn A" th√¨ gi·ªØ nguy√™n
    return s

JSON_PATTERN = re.compile(r"\{[\s\S]*\}", re.MULTILINE)
def _try_load_json(maybe_json: str) -> Optional[Dict[str, Any]]:
    """
    C·ªë g·∫Øng parse JSON t·ª´ m·ªôt chu·ªói:
    - Th·ª≠ loads tr·ª±c ti·∫øp
    - N·∫øu th·∫•t b·∫°i, t√¨m kh·ªëi {...} l·ªõn nh·∫•t trong text r·ªìi parse
    """
    if not isinstance(maybe_json, str):
        return None
    # 1) th·ª≠ parse tr·ª±c ti·∫øp
    try:
        return json.loads(maybe_json)
    except Exception:
        pass
    # 2) th·ª≠ b·∫Øt kh·ªëi JSON { ... }
    m = JSON_PATTERN.search(maybe_json)
    if m:
        try:
            return json.loads(m.group(0))
        except Exception:
            return None
    return None

BACKOFFS = [0.6, 1.2, 2.4, 4.8]  # exponential backoff with jitter

def _safe_request(session: requests.Session, url: str, payload: dict, headers: dict, timeout: int = 30):
    """
    G·ªçi Gemini v·ªõi retry/backoff cho c√°c l·ªói 429/5xx.
    Tr·∫£ v·ªÅ response.json() n·∫øu OK, ho·∫∑c raise n·∫øu h·∫øt retry.
    """
    last_exc = None
    for i, base in enumerate(BACKOFFS):
        try:
            resp = session.post(url, json=payload, headers=headers, timeout=timeout)
            if resp.status_code == 200:
                return resp.json()
            # 429 / 5xx => backoff
            if resp.status_code in (429, 500, 502, 503, 504):
                # ng·ªß r·ªìi th·ª≠ l·∫°i
                jitter = random.uniform(0, 0.3)
                time.sleep(base + jitter)
                last_exc = requests.HTTPError(f"{resp.status_code} {resp.reason}")
                continue
            # c√≤n l·∫°i raise lu√¥n
            resp.raise_for_status()
        except requests.RequestException as e:
            # network l·ªói: th·ª≠ l·∫°i n·∫øu c√≤n l∆∞·ª£t
            last_exc = e
            jitter = random.uniform(0, 0.3)
            time.sleep(base + jitter)
    # h·∫øt retry
    if last_exc:
        raise last_exc
    raise RuntimeError("Unknown request failure")

def _coerce_question_dict(text_or_dict) -> Optional[dict]:
    """
    Chu·∫©n ho√° c√¢u h·ªèi t·ª´ Gemini v·ªÅ dict:
    - N·∫øu l√† dict: tr·∫£ th·∫≥ng (ch·ªâ pick c√°c field c·∫ßn).
    - N·∫øu l√† string JSON: json.loads r·ªìi tr·∫£ dict.
    - N·∫øu l√† string th∆∞·ªùng ch·ª©a JSON: strip v√† c·ªë json.loads.
    - Kh√¥ng valid => None.
    """
    if text_or_dict is None:
        return None

    # Tr∆∞·ªùng h·ª£p content ƒë√£ l√† dict v·ªõi keys chu·∫©n
    if isinstance(text_or_dict, dict):
        q_text = (text_or_dict.get("question_text") or "").strip()
        q_type = (text_or_dict.get("question_type") or text_or_dict.get("type") or "").strip()
        options = text_or_dict.get("options") or []
        return {
            "question_text": q_text,
            "question_type": q_type or "open_ended",
            "options": options if isinstance(options, list) else []
        }

    # N·∫øu l√† string -> c·ªë parse JSON
    if isinstance(text_or_dict, str):
        s = text_or_dict.strip()
        # Gemini hay tr·∫£ ph·∫ßn text l√† JSON string c·ªßa 1 object
        if s.startswith("{") and s.endswith("}"):
            try:
                data = json.loads(s)
                return _coerce_question_dict(data)
            except Exception:
                return None
        # C√≥ th·ªÉ b·ªçc th√™m text kh√°c -> c·ªë t√¨m JSON object ƒë·∫ßu ti√™n
        first = s.find("{")
        last = s.rfind("}")
        if first != -1 and last != -1 and last > first:
            maybe = s[first:last+1]
            try:
                data = json.loads(maybe)
                return _coerce_question_dict(data)
            except Exception:
                return None
        return None

    # ki·ªÉu kh√°c th√¨ b·ªè
    return None

class GeminiClient:
    def __init__(self, config: GeminiConfig):
        self.config = config
        self.headers = {
            "Content-Type": "application/json"
        }

    def _coerce_option_list(self, options) -> list[str]:
        """Tr·∫£ v·ªÅ list[str] s·∫°ch; ch·∫•p nh·∫≠n [], list[str], list[dict]."""
        if not options:
            return []
        out = []
        if isinstance(options, list):
            for o in options:
                if isinstance(o, dict):
                    t = (o.get("option_text") or "").strip()
                    if t:
                        out.append(t)
                elif isinstance(o, str):
                    s = o.strip()
                    if s:
                        # c·∫Øt noise ki·ªÉu `option_text='X'` n·∫øu model l·ª° tr·∫£
                        m = re.search(r"option_text\s*[:=]\s*['\"]([^'\"]+)['\"]", s, flags=re.I)
                        out.append(m.group(1).strip() if m else s)
        elif isinstance(options, str):
            s = options.strip()
            if s:
                out.append(s)
        return out

    def _is_placeholder_question(self, text: str) -> bool:
        low = (text or "").strip().lower()
        return (not low) or low.startswith("c√¢u h·ªèi ") or low.startswith("question ") or low in {"placeholder", "sample question"}
    

    def generate_survey(self, prompt: str, context: Optional[Dict[str, Any]] = None):
        try:
            texts = self._call_gemini_api(
                prompt if not context else f"{prompt}\n\nNg·ªØ c·∫£nh: {context}",
                candidate_count=3,
                max_output_tokens=3072,          # tƒÉng l√™n 3072 ƒë·ªÉ tr√°nh c·∫Øt JSON (m·ªói c√¢u ~200-300 tokens)
                response_schema=SURVEY_SCHEMA
            )
            if not texts:
                return None

            best = None
            best_score = -1
            for t in texts:
                parsed = self._parse_survey_response(t)
                if not parsed or not getattr(parsed, "questions", None):
                    continue

                # ch·∫•m ƒë·ªô ‚Äúƒë·ªß v√† s·∫°ch‚Äù: s·ªë c√¢u h·ª£p l·ªá & kh√¥ng placeholder
                ok = 0
                for q in parsed.questions:
                    qt = (getattr(q, "question_text", "") or "").strip().lower()
                    if qt and not qt.startswith("c√¢u h·ªèi "):
                        ok += 1
                if ok > best_score:
                    best, best_score = parsed, ok

            return best

        except requests.HTTPError as e:
            if e.response is not None and e.response.status_code == 429:
                # ƒë·ª´ng crash, tr·∫£ None ƒë·ªÉ t·∫ßng tr√™n fallback
                return None
            raise


    
    def generate_one_question(
        self,
        title: str = "",
        category: str = "general",
        question_type: Optional[str] = None,
        ai_prompt: str = "",
        previous_question: str = ""
    ) -> Dict[str, Any]:
        try:
            req_type = (question_type or "").strip().lower().replace("-", "_").replace(" ", "_")
            guide = [
                "B·∫°n l√† chuy√™n gia t·∫°o c√¢u h·ªèi kh·∫£o s√°t.",
                f"Ch·ªß ƒë·ªÅ: {title or '(kh√¥ng c√≥)'}",
                f"Danh m·ª•c: {category or 'general'}",
                (f"Lo·∫°i c√¢u h·ªèi y√™u c·∫ßu: {req_type}" if req_type else ""),
                "Ch·ªâ t·∫°o 1 c√¢u, r√µ r√†ng, kh√¥ng d√πng placeholder ki·ªÉu 'C√¢u h·ªèi 1'.",
                "Tr·∫£ v·ªÅ JSON: {question_text, question_type, options?}.",
                "V·ªõi open_ended/rating/boolean_/date_time/file_upload: options = [].",
                "V·ªõi single_choice/multiple_choice/ranking: sinh 3‚Äì5 l·ª±a ch·ªçn th·ª±c t·∫ø."
            ]
            
            # ‚ú® PROMPT ƒê·∫∂C BI·ªÜT CHO RANKING: Y√™u c·∫ßu t·ªëi thi·ªÉu 5 options
            if req_type == "ranking":
                guide.append("‚ö†Ô∏è QUAN TR·ªåNG: Lo·∫°i 'ranking' B·∫ÆT BU·ªòC ph·∫£i c√≥ T·ªêI THI·ªÇU 5 options (kh√¥ng ƒë∆∞·ª£c d∆∞·ªõi 5).")
                guide.append("V√≠ d·ª• ranking options: ['R·∫•t quan tr·ªçng', 'Quan tr·ªçng', 'B√¨nh th∆∞·ªùng', '√çt quan tr·ªçng', 'Kh√¥ng quan tr·ªçng']")
                guide.append("Ho·∫∑c ranking theo th·ª© t·ª± ∆∞u ti√™n: ['∆Øu ti√™n cao nh·∫•t', '∆Øu ti√™n cao', '∆Øu ti√™n trung b√¨nh', '∆Øu ti√™n th·∫•p', '∆Øu ti√™n th·∫•p nh·∫•t']")
            
            if previous_question:
                guide.append(f"Kh√¥ng l·∫∑p l·∫°i/di·ªÖn ƒë·∫°t gi·ªëng c√¢u tr∆∞·ªõc: \"{previous_question}\"")
            if ai_prompt:
                guide.append(ai_prompt.strip())

            minimal_prompt = "\n".join([s for s in guide if s])

            texts = self._call_gemini_api(
                minimal_prompt,
                max_output_tokens=512,
                candidate_count=1,
                response_schema=ONE_QUESTION_SCHEMA
            )
            if not texts:
                return {}

            def _is_placeholder(s: str) -> bool:
                low = (s or "").strip().lower()
                return (not low) or low.startswith("c√¢u h·ªèi ") or low.startswith("question ")

            for t in texts:
                json_text = self._extract_json_from_text(t)
                if not json_text:
                    continue
                try:
                    data = json.loads(json_text)
                except Exception:
                    continue

                if isinstance(data, dict) and "question_text" in data:
                    item = data
                elif isinstance(data, dict) and "questions" in data:
                    qs = data.get("questions") or []
                    item = qs[0] if qs else {}
                elif isinstance(data, list):
                    item = data[0] if data else {}
                else:
                    item = {}

                q_text = (item.get("question_text") or item.get("text") or item.get("question") or "").strip()
                if _is_placeholder(q_text):
                    continue

                q_type = (item.get("question_type") or item.get("type") or (req_type or "open_ended")).strip().lower().replace("-", "_").replace(" ", "_")
                options = item.get("options") or []
                if q_type in {"open_ended", "rating", "boolean_", "date_time", "file_upload"}:
                    options = []

                return {"question_text": q_text, "question_type": q_type, "options": options}

            return {}

        except Exception as e:
            logger.error("L·ªói khi t·∫°o 1 c√¢u h·ªèi v·ªõi Gemini: %s", e)
            return {}


    def _build_survey_prompt(self, user_prompt: str, context: Dict[str, Any] = None) -> str:
        """X√¢y d·ª±ng prompt to√†n di·ªán cho Gemini API"""
        
        # L·∫•y s·ªë l∆∞·ª£ng c√¢u h·ªèi t·ª´ context ho·∫∑c m·∫∑c ƒë·ªãnh 5
        num_questions = context.get('number_of_questions', 5) if context else 5
        
        # T·∫°o v√≠ d·ª• c√¢u h·ªèi d·ª±a tr√™n s·ªë l∆∞·ª£ng y√™u c·∫ßu
        example_questions = []
        for i in range(min(num_questions, 2)):  # T·ªëi ƒëa 2 v√≠ d·ª•
            if i == 0:
                example_questions.append(f'''        {{
            "question_text": "C√¢u h·ªèi {i+1}",
            "question_type": "multiple_choice",
            "is_required": true,
            "display_order": {i+1},
            "options": [
                {{"option_text": "L·ª±a ch·ªçn A", "display_order": 1}},
                {{"option_text": "L·ª±a ch·ªçn B", "display_order": 2}}
            ]
        }}''')
            else:
                example_questions.append(f'''        {{
            "question_text": "C√¢u h·ªèi {i+1}", 
            "question_type": "open_ended",
            "is_required": false,
            "display_order": {i+1},
            "options": []
        }}''')
        
        questions_example = ",\n".join(example_questions)
        
        base_prompt = f"""B·∫°n l√† chuy√™n gia thi·∫øt k·∫ø kh·∫£o s√°t. T·∫°o kh·∫£o s√°t cho: {user_prompt}

QUAN TR·ªåNG: Ch·ªâ tr·∫£ v·ªÅ JSON h·ª£p l·ªá, kh√¥ng c√≥ text th√™m.
QUAN TR·ªåNG: T·∫°o CH√çNH X√ÅC {num_questions} c√¢u h·ªèi, kh√¥ng h∆°n kh√¥ng k√©m.

{{
    "title": "Ti√™u ƒë·ªÅ kh·∫£o s√°t",
    "description": "M√¥ t·∫£ m·ª•c ƒë√≠ch kh·∫£o s√°t", 
    "questions": [
{questions_example}
    ]
}}

T·∫°o CH√çNH X√ÅC {num_questions} c√¢u h·ªèi. D√πng multiple_choice, open_ended, rating, boolean_, date_time, file_upload. V·ªõi open_ended/rating/boolean_/date_time/file_upload th√¨ options = []."""

        # Th√™m context n·∫øu ƒë∆∞·ª£c cung c·∫•p
        if context:
            if context.get('title_hint'):
                base_prompt += f" Ti√™u ƒë·ªÅ kh·∫£o s√°t: '{context['title_hint']}'."
            if context.get('description_hint'):
                base_prompt += f" M√¥ t·∫£: '{context['description_hint']}'."
            if context.get('category'):
                base_prompt += f" Lƒ©nh v·ª±c: {context['category']}."
            if context.get('target_audience'):
                base_prompt += f" ƒê·ªëi t∆∞·ª£ng: {context['target_audience']}."
        
        return base_prompt
    
    def _call_gemini_api(
        self,
        prompt: str,
        max_output_tokens: int = 1024,
        candidate_count: int = 1,
        response_schema: Optional[dict] = None,
        model_name: Optional[str] = None,
    ) -> list[str]:
        """
        G·ªçi Gemini v·ªõi structured output, retry/backoff cho 429/5xx.
        Tr·∫£ danh s√°ch text JSON (ho·∫∑c inlineData JSON ƒë√£ decode) t·ª´ c√°c candidates.
        """
        model = model_name or self.config.model  # d√πng field th·ªëng nh·∫•t
        url = f"{self.config.base_url}/models/{model}:generateContent?key={self.config.api_key}"

        payload = {
            "contents": [{"parts": [{"text": prompt}]}],
            "generationConfig": {
                "temperature": getattr(self.config, "temperature", 0.4),
                "maxOutputTokens": max_output_tokens,
                "candidateCount": max(1, min(int(candidate_count), 4)),  # clamp 1..3
                "responseMimeType": "application/json",
            }
        }
        if response_schema:
            payload["generationConfig"]["responseSchema"] = response_schema

        RETRY_CODES = {429, 500, 502, 503, 504}
        backoff = 0.8
        attempts = 0
        last_err = None

        while attempts < 3:
            try:
                r = requests.post(url, headers=self.headers, json=payload, timeout=40)
                if r.status_code in RETRY_CODES:
                    last_err = f"{r.status_code} {r.text[:200]}"
                    attempts += 1
                    time.sleep(backoff + random.uniform(0, 0.3))
                    backoff *= 2
                    continue

                r.raise_for_status()
                data = r.json()

                out: list[str] = []
                for c in (data.get("candidates") or []):
                    parts = ((c.get("content") or {}).get("parts") or [])
                    for p in parts:
                        if isinstance(p, dict) and p.get("text"):
                            out.append(p["text"])
                        elif isinstance(p, dict) and p.get("inlineData"):
                            inline = p["inlineData"]
                            mime = inline.get("mimeType", "")
                            if "json" in mime.lower() and inline.get("data"):
                                try:
                                    decoded = base64.b64decode(inline["data"]).decode("utf-8", "ignore")
                                    if decoded:
                                        out.append(decoded)
                                except Exception:
                                    pass
                return out

            except requests.RequestException as e:
                last_err = str(e)
                attempts += 1
                time.sleep(backoff + random.uniform(0, 0.3))
                backoff *= 2

        # Fallback model chain n·∫øu v·∫´n fail (ƒë·∫∑c bi·ªát 429/503)
        # QUAN TR·ªåNG: Ph·∫£i d√πng model ƒë∆∞·ª£c truy·ªÅn v√†o (model_name) ho·∫∑c model m·∫∑c ƒë·ªãnh
        current_model = model_name or self.config.model
        
        # Ch·ªâ fallback khi g·∫∑p rate limit (429) ho·∫∑c server error (503/500)
        if any(code in str(last_err) for code in ["429", "503", "500"]):
            # T√¨m v·ªã tr√≠ model hi·ªán t·∫°i trong fallback chain
            try:
                current_idx = self.config.fallback_models.index(current_model)
            except ValueError:
                # Model hi·ªán t·∫°i kh√¥ng c√≥ trong chain ‚Üí b·∫Øt ƒë·∫ßu t·ª´ ƒë·∫ßu
                current_idx = -1
            
            # Th·ª≠ c√°c models c√≤n l·∫°i trong chain
            for next_model in self.config.fallback_models[current_idx + 1:]:
                logger.warning(
                    f"‚ö†Ô∏è Model '{current_model}' g·∫∑p l·ªói {last_err[:100]}. "
                    f"Fallback sang '{next_model}'..."
                )
                try:
                    # RECURSIVE CALL v·ªõi model m·ªõi - s·∫Ω kh√¥ng loop v√¨ current_idx tƒÉng d·∫ßn
                    result = self._call_gemini_api(
                        prompt,
                        max_output_tokens=max_output_tokens,
                        candidate_count=candidate_count,
                        response_schema=response_schema,
                        model_name=next_model  # Truy·ªÅn model m·ªõi xu·ªëng
                    )
                    logger.info(f"‚úÖ Fallback th√†nh c√¥ng v·ªõi model '{next_model}'")
                    return result
                except Exception as e:
                    logger.error(f"‚ùå Fallback '{next_model}' th·∫•t b·∫°i: {str(e)[:100]}")
                    continue
            
            logger.error(f"üí• ƒê√£ th·ª≠ h·∫øt {len(self.config.fallback_models)} models trong fallback chain")

        raise RuntimeError(f"Gemini API unavailable after retries. Last error: {last_err}")



    def _sanitize_questions_payload(self, payload: dict) -> dict:
        """
        Chu·∫©n ho√° d·ªØ li·ªáu t·ª´ Gemini tr∆∞·ªõc khi validate b·∫±ng Pydantic.
        KH√îNG t·ª± b∆°m A/B cho MCQ/Single. Ch·ªâ xo√° options cho c√°c lo·∫°i kh√¥ng-option.
        """
        NON_OPTION_TYPES = {"open_ended", "rating", "boolean_", "date_time", "file_upload"}
        questions = payload.get("questions", []) or []

        for q in questions:
            raw = (q.get("question_type") or "").strip().lower().replace("-", "_").replace(" ", "_")
            if raw in ["boolean", "yes_no", "true_false"]:
                qtype = "boolean_"
            elif raw in ["date", "datetime", "time", "time_picker", "date_time"]:
                qtype = "date_time"
            elif raw in ["file", "upload", "attachment", "file_upload"]:
                qtype = "file_upload"
            elif raw in ["single", "singlechoice", "radio"]:
                qtype = "single_choice"
            elif raw in ["mcq", "multiple", "multi_choice", "checkbox"]:
                qtype = "multiple_choice"
            else:
                qtype = raw or "open_ended"
            q["question_type"] = qtype

            if qtype in NON_OPTION_TYPES:
                q["options"] = []
            else:
                # gi·ªØ nguy√™n options do AI tr·∫£; chu·∫©n ho√° format n·∫øu c·∫ßn
                opts = q.get("options") or []
                norm = []
                for i, o in enumerate(opts, start=1):
                    if isinstance(o, dict):
                        t = (o.get("option_text") or o.get("text") or o.get("label") or "").strip()
                    else:
                        t = str(o).strip()
                    if t:
                        norm.append({"option_text": t, "display_order": i})
                q["options"] = norm

            q["is_required"] = bool(q.get("is_required", True))

        payload["questions"] = questions
        return payload

    
    def _parse_survey_response(self, response_text: str) -> Optional[GeneratedSurveyResponse]:
        try:
            json_text = self._extract_json_from_text(response_text)
            if not json_text:
                preview = (response_text or "")[:300].replace("\n", " ")
                logger.warning(f"[gemini] ‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y JSON block. Preview (300 chars): {preview}")
                # th·ª≠ s·ª≠a JSON b·ªã c·∫Øt c·ª•t r·ªìi parse l·∫°i
                fixed = self._fix_incomplete_json(response_text or "")
                try:
                    data = json.loads(fixed)
                    logger.info(f"[gemini] ‚úÖ ƒê√£ s·ª≠a ƒë∆∞·ª£c JSON b·ªã c·∫Øt: {len(fixed)} chars")
                except Exception as e:
                    logger.error(f"[gemini] ‚ùå Fix JSON th·∫•t b·∫°i: {e}. Raw length: {len(response_text or '')}")
                    raise ValueError("Kh√¥ng t√¨m th·∫•y JSON trong ph·∫£n h·ªìi")
            else:
                data = json.loads(json_text)

            normalized_data = self._normalize_survey_data(data)
            normalized_data = self._sanitize_questions_payload(normalized_data)
            if not normalized_data.get("questions"):
                return None

            return GeneratedSurveyResponse(**normalized_data)

        except json.JSONDecodeError as e:
            logger.error(f"L·ªói ph√¢n t√≠ch JSON: {str(e)}")
            logger.error(f"VƒÉn b·∫£n ph·∫£n h·ªìi: {response_text}")
            return None
        except Exception as e:
            logger.error(f"L·ªói khi ph√¢n t√≠ch ph·∫£n h·ªìi kh·∫£o s√°t: {str(e)}")
            return None


    def _extract_json_from_text(self, text: str) -> str | None:
        """
        B√≥c JSON t·ª´ ph·∫£n h·ªìi LLM theo ki·ªÉu 'ch·ªãu l·ªói':
        - ∆Øu ti√™n kh·ªëi ```json ... ``` ho·∫∑c ``` ... ```
        - N·∫øu kh√¥ng c√≥, l·∫•y t·ª´ d·∫•u '{' ƒë·∫ßu ti√™n ƒë·∫øn '}' cu·ªëi c√πng (c√¢n b·∫±ng ngo·∫∑c)
        - N·∫øu JSON b·ªã c·∫Øt, th·ª≠ s·ª≠a b·∫±ng _fix_incomplete_json()
        """
        if not text:
            return None
        t = text.strip()

        # 1) ```json ... ```
        m = re.search(r"```json\s*(\{[\s\S]+?\})\s*```", t, flags=re.I)
        if m:
            return m.group(1)

        # 2) ``` ... ```
        m = re.search(r"```\s*(\{[\s\S]+?\})\s*```", t, flags=re.I)
        if m:
            return m.group(1)

        # 3) C·∫Øt theo d·∫•u ngo·∫∑c nh·ªçn c√¢n b·∫±ng
        start = t.find("{")
        end   = t.rfind("}")
        if start != -1 and end != -1 and end > start:
            candidate = t[start:end+1]

            # C√¢n b·∫±ng ngo·∫∑c th√¥: lo·∫°i b·ªè ph·∫ßn th·ª´a khi b·ªã c·∫Øt ƒëu√¥i do MAX_TOKENS
            open_cnt = candidate.count("{")
            close_cnt = candidate.count("}")
            if close_cnt > open_cnt:
                # c√≥ th·ªÉ th·ª´a }, gi·ªØ nguy√™n
                pass
            elif open_cnt > close_cnt:
                # thi·∫øu }, th·ª≠ fix
                fixed = self._fix_incomplete_json(candidate)
                try:
                    json.loads(fixed)  # validate
                    return fixed
                except Exception:
                    return None
            return candidate

        return None


    def _fix_incomplete_json(self, json_str: str) -> str:
        """C·ªë g·∫Øng s·ª≠a JSON b·ªã c·∫Øt b·∫±ng c√°ch th√™m d·∫•u ƒë√≥ng ngo·∫∑c v√† xo√° string ch∆∞a ƒë√≥ng"""
        if not json_str:
            return json_str
        
        result = json_str
        
        # Xo√° string literals ch∆∞a ƒë√≥ng ·ªü cu·ªëi (v√≠ d·ª•: "text": "ƒê·∫ø m·ªèng gi)
        # T√¨m d·∫•u " cu·ªëi c√πng
        last_quote = result.rfind('"')
        if last_quote != -1:
            # ƒê·∫øm s·ªë d·∫•u " tr∆∞·ªõc ƒë√≥ ƒë·ªÉ xem c√≥ l·∫ª kh√¥ng
            quotes_before = result[:last_quote].count('"')
            if quotes_before % 2 == 0:  # n·∫øu ch·∫µn ‚Üí d·∫•u " cu·ªëi l√† m·ªü
                # C·∫Øt b·ªè string ch∆∞a ƒë√≥ng
                result = result[:last_quote].rstrip(',').rstrip()
            
        # ƒê·∫øm s·ªë d·∫•u m·ªü v√† ƒë√≥ng
        open_braces = result.count('{')
        close_braces = result.count('}')
        open_brackets = result.count('[')
        close_brackets = result.count(']')
        
        # Th√™m d·∫•u ƒë√≥ng ngo·∫∑c vu√¥ng n·∫øu thi·∫øu
        for _ in range(open_brackets - close_brackets):
            result += ']'
            
        # Th√™m d·∫•u ƒë√≥ng ngo·∫∑c nh·ªçn n·∫øu thi·∫øu
        for _ in range(open_braces - close_braces):
            result += '}'
            
        return result

    def _normalize_survey_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Chu·∫©n ho√° ph·∫£n h·ªìi Gemini v·ªÅ ƒë·ªãnh d·∫°ng mong ƒë·ª£i.
        H·ªó tr·ª£ c·∫£ 2 d·∫°ng:
        - Object: { "title": ..., "description": ..., "questions": [...] }
        - List thu·∫ßn: [ {text/type/options}, ... ]
        """
        # 1) L·∫•y danh s√°ch raw questions b·∫•t k·ªÉ data l√† dict hay list
        if isinstance(data, list):
            questions_raw = data
            title = "Kh·∫£o s√°t"
            description = "M√¥ t·∫£ kh·∫£o s√°t"
        elif isinstance(data, dict):
            title = data.get('title') or data.get('surveyTitle') or data.get('survey_title', 'Kh·∫£o s√°t')
            description = data.get('description') or data.get('surveyDescription') or data.get('survey_description', 'M√¥ t·∫£ kh·∫£o s√°t')
            questions_raw = data.get('questions', []) or data.get('items', []) or data.get('qs', [])
        else:
            # format l·∫° -> r·ªóng
            title = "Kh·∫£o s√°t"
            description = "M√¥ t·∫£ kh·∫£o s√°t"
            questions_raw = []

        # 2) Chu·∫©n ho√° t·ª´ng c√¢u h·ªèi
        normalized_questions = []
        for i, q in enumerate(questions_raw or []):
            # q c√≥ th·ªÉ l√† dict ho·∫∑c string; ta ch·ªâ nh·∫≠n dict h·ª£p l·ªá
            if not isinstance(q, dict):
                continue
            normalized_q = {
                'question_text': q.get('question_text') or q.get('text') or q.get('question') or f'C√¢u h·ªèi {i+1}',
                'question_type': self._normalize_question_type(q.get('question_type') or q.get('type') or 'open_ended'),
                'is_required': q.get('is_required', q.get('required', True)),
                'display_order': i + 1,
                'options': self._normalize_options(q.get('options', [])),
            }
            normalized_questions.append(normalized_q)

        return {
            'title': title,
            'description': description,
            'questions': normalized_questions
        }


    def _normalize_question_type(self, qtype: str) -> str:
        qtype = qtype.lower()
        if qtype in ['radio', 'single', 'single_choice']:
            return 'single_choice'
        if qtype in ['multiple_choice','multiple','multi_choice','checkbox','mcq']:
            return 'multiple_choice'
        if qtype in ['text','textarea','open','open_ended']:
            return 'open_ended'
        if qtype in ['rating','scale']:
            return 'rating'
        if qtype in ['boolean','bool','yes_no','true_false']:
            return 'boolean_'
        if qtype in ['date','datetime','date_time','time','time_picker']:
            return 'date_time'
        if qtype in ['file','file_upload','upload','attachment']:
            return 'file_upload'
        return 'open_ended'


    def _normalize_options(self, options):
        out = []
        if not isinstance(options, list):
            return out
        for i, o in enumerate(options, start=1):
            if isinstance(o, dict):
                txt = (o.get("option_text") or "").strip()
            else:
                txt = _clean_option_text(str(o))
            if txt:
                out.append({"option_text": txt, "display_order": i})
        return out


# H√†m factory ƒë·ªÉ t·∫°o Gemini client
def create_gemini_client(api_key: str) -> GeminiClient:
    """H√†m factory ƒë·ªÉ t·∫°o Gemini client v·ªõi c·∫•u h√¨nh m·∫∑c ƒë·ªãnh"""
    # ƒê·ªçc model t·ª´ bi·∫øn m√¥i tr∆∞·ªùng, fallback v·ªÅ gemini-2.5-flash
    model = os.getenv("GEMINI_MODEL", "gemini-2.5-flash")
    config = GeminiConfig(api_key=api_key, model=model)
    return GeminiClient(config)